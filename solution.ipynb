{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79c9fe4",
   "metadata": {},
   "source": [
    "# Learning-to-Rank Model for E-commerce Search\n",
    "\n",
    "This notebook implements a Learning-to-Rank solution for ranking products in an e-commerce search engine.\n",
    "\n",
    "## Tasks\n",
    "1. **Part 1: Data analysis** - Calculate key data analysis metrics\n",
    "2. **Part 2: Learning-to-rank model** - Build and evaluate the ranking model\n",
    "3. **Part 3: Business summary** - Business analysis and recommendations\n",
    "\n",
    "## Model features\n",
    "- **Required features**:\n",
    "  - `position_boost = 1/position` (clipped at position 3)\n",
    "  - `log_price = log(price_pln + 1)`\n",
    "  - `quality_price_ratio = quality_score / log_price`\n",
    "  - `category_match = (category == user_preferred_category) ? 1 : 0`\n",
    "  - Additional session-relative and interaction features\n",
    "\n",
    "- **Advanced features**:\n",
    "  - Session-relative features (price/quality rankings within session)\n",
    "  - Smoothed CTR priors computed on the training split only (Bayesian m-estimate)\n",
    "  - Position-bias control via buckets\n",
    "  - Category interactions\n",
    "  - Robust cross-validation evaluation\n",
    "\n",
    "## Outputs\n",
    "- `results.json` - Complete analysis results\n",
    "- `predictions.csv` - Model predictions on the test split\n",
    "- `solution_summary.md` - Solution summary\n",
    "\n",
    "**Expected input:** `search_sessions.csv` in the same directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68293b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (67651, 8)\n",
      "Sessions: 8000\n",
      "Products: 67651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>position</th>\n",
       "      <th>clicked</th>\n",
       "      <th>price_pln</th>\n",
       "      <th>category</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>user_preferred_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.05</td>\n",
       "      <td>Elektronika</td>\n",
       "      <td>0.363</td>\n",
       "      <td>Elektronika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>249.63</td>\n",
       "      <td>Elektronika</td>\n",
       "      <td>0.547</td>\n",
       "      <td>Elektronika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>679.19</td>\n",
       "      <td>Elektronika</td>\n",
       "      <td>0.696</td>\n",
       "      <td>Elektronika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>493.38</td>\n",
       "      <td>Elektronika</td>\n",
       "      <td>0.100</td>\n",
       "      <td>Elektronika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2982.39</td>\n",
       "      <td>Odziez</td>\n",
       "      <td>0.384</td>\n",
       "      <td>Elektronika</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id product_id  position  clicked  price_pln     category  quality_score user_preferred_category\n",
       "0           0   prod_0_1         1        1      40.05  Elektronika          0.363             Elektronika\n",
       "1           0   prod_0_2         2        0     249.63  Elektronika          0.547             Elektronika\n",
       "2           0   prod_0_3         3        0     679.19  Elektronika          0.696             Elektronika\n",
       "3           0   prod_0_4         4        0     493.38  Elektronika          0.100             Elektronika\n",
       "4           0   prod_0_5         5        0    2982.39       Odziez          0.384             Elektronika"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install pandas numpy scikit-learn lightgbm matplotlib\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRanker, early_stopping, log_evaluation\n",
    "\n",
    "pd.set_option('display.max_columns', 400)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "DATA_PATH = \"search_sessions.csv\"\n",
    "assert os.path.exists(DATA_PATH), f\"Missing {DATA_PATH}. Put it next to this notebook.\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Basic coercions\n",
    "df[\"clicked\"] = df[\"clicked\"].astype(int)\n",
    "df[\"position\"] = df[\"position\"].astype(int)\n",
    "df[\"price_pln\"] = df[\"price_pln\"].astype(float)\n",
    "df[\"quality_score\"] = df[\"quality_score\"].astype(float)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Sessions: {df['session_id'].nunique()}\")\n",
    "print(f\"Products: {df['product_id'].nunique()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb5cfca",
   "metadata": {},
   "source": [
    "## Part 1: Data analysis\n",
    "\n",
    "Calculate the 5 key data analysis metrics required by the instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "723e3910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analysis Results:\n",
      "{\n",
      "  \"overall_ctr\": 0.0767,\n",
      "  \"position_bias_ratio\": 3.42,\n",
      "  \"electronics_ctr\": 0.1219,\n",
      "  \"quality_correlation\": 0.1198,\n",
      "  \"best_category\": \"Elektronika\"\n",
      "}\n",
      "\n",
      "CTR by position:\n",
      "position\n",
      "1     0.198625\n",
      "2     0.111000\n",
      "3     0.081500\n",
      "4     0.067375\n",
      "5     0.058000\n",
      "6     0.045318\n",
      "7     0.042628\n",
      "8     0.034455\n",
      "9     0.037443\n",
      "10    0.029592\n",
      "11    0.027211\n",
      "12    0.032191\n",
      "Name: clicked, dtype: float64\n",
      "\n",
      "CTR by category:\n",
      "category\n",
      "Elektronika    0.121921\n",
      "Ksiazki        0.036991\n",
      "Odziez         0.070694\n",
      "Name: clicked, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Data Analysis\n",
    "# Calculate the 5 required metrics\n",
    "\n",
    "# 1. overall_ctr: All clicks / all impressions\n",
    "overall_ctr = df[\"clicked\"].mean()\n",
    "\n",
    "# 2. position_bias_ratio: CTR position 1 / CTR position 5\n",
    "ctr_by_position = df.groupby(\"position\")[\"clicked\"].mean()\n",
    "position_bias_ratio = ctr_by_position[1] / ctr_by_position[5] if 5 in ctr_by_position.index and ctr_by_position[5] > 0 else 0.0\n",
    "\n",
    "# 3. electronics_ctr: CTR for category \"Elektronika\"\n",
    "electronics_ctr = df[df[\"category\"] == \"Elektronika\"][\"clicked\"].mean()\n",
    "\n",
    "# 4. quality_correlation: Correlation between quality_score and clicked\n",
    "quality_correlation = df[\"quality_score\"].corr(df[\"clicked\"])\n",
    "\n",
    "# 5. best_category: Category with highest CTR\n",
    "ctr_by_category = df.groupby(\"category\")[\"clicked\"].mean()\n",
    "best_category = ctr_by_category.idxmax()\n",
    "\n",
    "# Store results\n",
    "data_analysis = {\n",
    "    \"overall_ctr\": round(float(overall_ctr), 4),\n",
    "    \"position_bias_ratio\": round(float(position_bias_ratio), 2),\n",
    "    \"electronics_ctr\": round(float(electronics_ctr), 4),\n",
    "    \"quality_correlation\": round(float(quality_correlation), 4),\n",
    "    \"best_category\": str(best_category)\n",
    "}\n",
    "\n",
    "print(\"Data Analysis Results:\")\n",
    "print(json.dumps(data_analysis, indent=2))\n",
    "print(f\"\\nCTR by position:\\n{ctr_by_position}\")\n",
    "print(f\"\\nCTR by category:\\n{ctr_by_category}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645d431",
   "metadata": {},
   "source": [
    "## Part 2: Learning-to-rank model\n",
    "\n",
    "### Utilities and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ead8e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "\n",
    "# --- Metrics ---\n",
    "\n",
    "def ndcg_at_k(y_true, y_score, group_ids, k=5, ignore_no_positive=True):\n",
    "    \"\"\"Mean NDCG@k over groups.\n",
    "\n",
    "    - ignore_no_positive=True: skip sessions with no positive labels (IDCG=0)\n",
    "      This matches common LTR evaluation practice and typical library behavior.\n",
    "    - ignore_no_positive=False: include such sessions as 0.0.\n",
    "    \"\"\"\n",
    "    gdf = pd.DataFrame({\"g\": group_ids, \"y\": y_true, \"s\": y_score})\n",
    "    ndcgs = []\n",
    "    for _, part in gdf.groupby(\"g\", sort=False):\n",
    "        part = part.sort_values(\"s\", ascending=False)\n",
    "        rel = part[\"y\"].to_numpy()[:k]\n",
    "\n",
    "        discounts = np.log2(np.arange(2, rel.size + 2))\n",
    "        dcg = ((2**rel - 1) / discounts).sum()\n",
    "\n",
    "        ideal = np.sort(part[\"y\"].to_numpy())[::-1][:k]\n",
    "        idcg = ((2**ideal - 1) / discounts[: ideal.size]).sum()\n",
    "\n",
    "        if idcg == 0:\n",
    "            if ignore_no_positive:\n",
    "                continue\n",
    "            ndcgs.append(0.0)\n",
    "        else:\n",
    "            ndcgs.append(float(dcg / idcg))\n",
    "\n",
    "    return float(np.mean(ndcgs)) if ndcgs else 0.0\n",
    "\n",
    "\n",
    "# --- Splits & ordering ---\n",
    "\n",
    "def finalize_order(df):\n",
    "    \"\"\"Ensure stable ordering/contiguity by session_id before group size computation.\"\"\"\n",
    "    return df.sort_values([\"session_id\", \"position\", \"product_id\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def group_sizes(df, group_col=\"session_id\"):\n",
    "    # Requires df already sorted by group_col\n",
    "    return df.groupby(group_col, sort=False).size().to_numpy()\n",
    "\n",
    "\n",
    "def split_by_session(df, seed=42, test_size=0.2):\n",
    "    \"\"\"Split by session_id (no leakage). Returns (train_df, test_df).\"\"\"\n",
    "    sessions = df[\"session_id\"].unique()\n",
    "    train_sess, test_sess = train_test_split(sessions, test_size=test_size, random_state=seed, shuffle=True)\n",
    "    train_df = df[df[\"session_id\"].isin(train_sess)].copy()\n",
    "    test_df = df[df[\"session_id\"].isin(test_sess)].copy()\n",
    "    return finalize_order(train_df), finalize_order(test_df)\n",
    "\n",
    "\n",
    "def split_train_val_from_train(train_full_df, seed=42, val_fraction=0.1):\n",
    "    \"\"\"Create an internal validation split from the train portion only.\"\"\"\n",
    "    tr, va = split_by_session(train_full_df, seed=seed, test_size=val_fraction)\n",
    "    return tr, va\n",
    "\n",
    "\n",
    "# --- Feature utilities ---\n",
    "\n",
    "def m_estimate_ctr(train: pd.DataFrame, key_cols, label_col=\"clicked\", m=50.0):\n",
    "    prior = float(train[label_col].mean())\n",
    "    agg = train.groupby(key_cols, observed=False)[label_col].agg([\"sum\", \"count\"]).reset_index()\n",
    "    agg[\"ctr_prior\"] = (agg[\"sum\"] + m * prior) / (agg[\"count\"] + m)\n",
    "    return agg[key_cols + [\"ctr_prior\"]], float(prior)\n",
    "\n",
    "\n",
    "def clip_series(s, lo=-3.0, hi=3.0):\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "\n",
    "def zscore_in_group(x: pd.Series) -> pd.Series:\n",
    "    mu = x.mean()\n",
    "    std = x.std(ddof=0)\n",
    "    if (not np.isfinite(std)) or std <= 0:\n",
    "        return pd.Series(np.zeros(len(x), dtype=float), index=x.index)\n",
    "    out = (x - mu) / std\n",
    "    return out.replace([np.inf, -np.inf], 0.0).fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c443ed5",
   "metadata": {},
   "source": [
    "## 2) Feature Engineering v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30463f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature count: 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>clicked</th>\n",
       "      <th>pos_boost_clipped3</th>\n",
       "      <th>posb_top3</th>\n",
       "      <th>posb_mid46</th>\n",
       "      <th>posb_bot710</th>\n",
       "      <th>log_price</th>\n",
       "      <th>quality_price_ratio</th>\n",
       "      <th>category_match</th>\n",
       "      <th>price_rank_in_session</th>\n",
       "      <th>quality_rank_in_session</th>\n",
       "      <th>price_pct_in_session</th>\n",
       "      <th>quality_pct_in_session</th>\n",
       "      <th>price_minus_session_median</th>\n",
       "      <th>quality_minus_session_mean</th>\n",
       "      <th>price_z_in_session_clipped</th>\n",
       "      <th>quality_z_in_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.714791</td>\n",
       "      <td>0.097717</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>-453.33</td>\n",
       "      <td>-0.146364</td>\n",
       "      <td>-0.697457</td>\n",
       "      <td>-0.636561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.523978</td>\n",
       "      <td>0.099023</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>-243.75</td>\n",
       "      <td>0.037636</td>\n",
       "      <td>-0.431507</td>\n",
       "      <td>0.163687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.522372</td>\n",
       "      <td>0.106710</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>185.81</td>\n",
       "      <td>0.186636</td>\n",
       "      <td>0.113590</td>\n",
       "      <td>0.811715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6.203304</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.409364</td>\n",
       "      <td>-0.122197</td>\n",
       "      <td>-1.780395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>prod_0_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8.000816</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>2489.01</td>\n",
       "      <td>-0.125364</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.545229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id product_id  clicked  pos_boost_clipped3  posb_top3  posb_mid46  posb_bot710  log_price  quality_price_ratio  category_match  price_rank_in_session  quality_rank_in_session  \\\n",
       "0           0   prod_0_1        1            1.000000       True       False        False   3.714791             0.097717               1                    1.0                      9.0   \n",
       "1           0   prod_0_2        0            0.500000       True       False        False   5.523978             0.099023               1                    5.0                      6.0   \n",
       "2           0   prod_0_3        0            0.333333       True       False        False   6.522372             0.106710               1                   10.0                      3.0   \n",
       "3           0   prod_0_4        0            0.333333      False        True        False   6.203304             0.016120               1                    6.0                     11.0   \n",
       "4           0   prod_0_5        0            0.333333      False        True        False   8.000816             0.047995               0                   11.0                      8.0   \n",
       "\n",
       "   price_pct_in_session  quality_pct_in_session  price_minus_session_median  quality_minus_session_mean  price_z_in_session_clipped  quality_z_in_session  \n",
       "0              0.090909                0.818182                     -453.33                   -0.146364                   -0.697457             -0.636561  \n",
       "1              0.454545                0.545455                     -243.75                    0.037636                   -0.431507              0.163687  \n",
       "2              0.909091                0.272727                      185.81                    0.186636                    0.113590              0.811715  \n",
       "3              0.545455                1.000000                        0.00                   -0.409364                   -0.122197             -1.780395  \n",
       "4              1.000000                0.727273                     2489.01                   -0.125364                    3.000000             -0.545229  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_position_features(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = d.copy()\n",
    "    out[\"position_bucket\"] = pd.cut(\n",
    "        out[\"position\"],\n",
    "        bins=[0,3,6,10],\n",
    "        labels=[\"top3\",\"mid46\",\"bot710\"],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    pb = pd.get_dummies(out[\"position_bucket\"], prefix=\"posb\")\n",
    "    out = pd.concat([out, pb], axis=1)\n",
    "    out[\"pos_boost_clipped3\"] = 1.0 / out[\"position\"].clip(upper=3).astype(float)\n",
    "    return out\n",
    "\n",
    "def session_relative_features(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = d.copy()\n",
    "    out[\"session_size\"] = out.groupby(\"session_id\")[\"product_id\"].transform(\"size\")\n",
    "\n",
    "    # price: lower is \"better\" (rank 1 = cheapest)\n",
    "    out[\"price_rank_in_session\"] = out.groupby(\"session_id\")[\"price_pln\"].rank(method=\"average\", ascending=True)\n",
    "    out[\"price_pct_in_session\"] = out[\"price_rank_in_session\"] / out[\"session_size\"].replace(0, 1)\n",
    "    out[\"price_min_in_session\"] = out.groupby(\"session_id\")[\"price_pln\"].transform(\"min\")\n",
    "    out[\"price_max_in_session\"] = out.groupby(\"session_id\")[\"price_pln\"].transform(\"max\")\n",
    "    out[\"is_cheapest_in_session\"] = (out[\"price_pln\"] == out[\"price_min_in_session\"]).astype(int)\n",
    "    out[\"is_most_expensive_in_session\"] = (out[\"price_pln\"] == out[\"price_max_in_session\"]).astype(int)\n",
    "\n",
    "    out[\"price_median_in_session\"] = out.groupby(\"session_id\")[\"price_pln\"].transform(\"median\")\n",
    "    out[\"price_minus_session_median\"] = out[\"price_pln\"] - out[\"price_median_in_session\"]\n",
    "\n",
    "    out[\"price_z_in_session\"] = out.groupby(\"session_id\")[\"price_pln\"].transform(zscore_in_group).astype(float)\n",
    "    out[\"price_z_in_session_clipped\"] = clip_series(out[\"price_z_in_session\"], -3, 3)\n",
    "\n",
    "    # quality: higher is \"better\" (rank 1 = highest quality)\n",
    "    out[\"quality_rank_in_session\"] = out.groupby(\"session_id\")[\"quality_score\"].rank(method=\"average\", ascending=False)\n",
    "    out[\"quality_pct_in_session\"] = out[\"quality_rank_in_session\"] / out[\"session_size\"].replace(0, 1)\n",
    "    out[\"quality_min_in_session\"] = out.groupby(\"session_id\")[\"quality_score\"].transform(\"min\")\n",
    "    out[\"quality_max_in_session\"] = out.groupby(\"session_id\")[\"quality_score\"].transform(\"max\")\n",
    "    out[\"is_best_quality_in_session\"] = (out[\"quality_score\"] == out[\"quality_max_in_session\"]).astype(int)\n",
    "    out[\"is_worst_quality_in_session\"] = (out[\"quality_score\"] == out[\"quality_min_in_session\"]).astype(int)\n",
    "\n",
    "    out[\"quality_mean_in_session\"] = out.groupby(\"session_id\")[\"quality_score\"].transform(\"mean\")\n",
    "    out[\"quality_minus_session_mean\"] = out[\"quality_score\"] - out[\"quality_mean_in_session\"]\n",
    "\n",
    "    out[\"quality_z_in_session\"] = out.groupby(\"session_id\")[\"quality_score\"].transform(zscore_in_group).astype(float)\n",
    "\n",
    "    out[\"category_freq_in_session\"] = out.groupby([\"session_id\", \"category\"])[\"product_id\"].transform(\"size\")\n",
    "\n",
    "    counts = out.groupby([\"session_id\", \"category\"], observed=False).size().reset_index(name=\"cnt\")\n",
    "    counts[\"max_cnt\"] = counts.groupby(\"session_id\")[\"cnt\"].transform(\"max\")\n",
    "    counts[\"is_majority_category\"] = (counts[\"cnt\"] == counts[\"max_cnt\"]).astype(int)\n",
    "    out = out.merge(counts[[\"session_id\", \"category\", \"is_majority_category\"]], on=[\"session_id\", \"category\"], how=\"left\")\n",
    "    out[\"is_majority_category\"] = out[\"is_majority_category\"].fillna(0).astype(int)\n",
    "\n",
    "    return out\n",
    "\n",
    "def add_core_features(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = d.copy()\n",
    "    out[\"log_price\"] = np.log(out[\"price_pln\"] + 1.0)\n",
    "    out[\"category_match\"] = (out[\"category\"] == out[\"user_preferred_category\"]).astype(int)\n",
    "    out[\"quality_price_ratio\"] = out[\"quality_score\"] / out[\"log_price\"].replace(0.0, EPS)\n",
    "    return out\n",
    "\n",
    "def one_hot_categories(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    cat_train = pd.get_dummies(train[\"category\"], prefix=\"cat\")\n",
    "    pref_train = pd.get_dummies(train[\"user_preferred_category\"], prefix=\"pref\")\n",
    "\n",
    "    cat_test = pd.get_dummies(test[\"category\"], prefix=\"cat\").reindex(columns=cat_train.columns, fill_value=0)\n",
    "    pref_test = pd.get_dummies(test[\"user_preferred_category\"], prefix=\"pref\").reindex(columns=pref_train.columns, fill_value=0)\n",
    "\n",
    "    train2 = pd.concat([train, cat_train, pref_train], axis=1)\n",
    "    test2  = pd.concat([test, cat_test, pref_test], axis=1)\n",
    "    return train2, test2, list(cat_train.columns), list(pref_train.columns)\n",
    "\n",
    "def add_ctr_priors(train: pd.DataFrame, test: pd.DataFrame, m=50.0):\n",
    "    global_ctr = train[\"clicked\"].mean()\n",
    "\n",
    "    map_cat, _ = m_estimate_ctr(train, [\"category\"], m=m)\n",
    "    train = train.merge(map_cat.rename(columns={\"ctr_prior\":\"ctr_prior_category\"}), on=[\"category\"], how=\"left\")\n",
    "    test  = test.merge(map_cat.rename(columns={\"ctr_prior\":\"ctr_prior_category\"}), on=[\"category\"], how=\"left\")\n",
    "\n",
    "    map_cxp, _ = m_estimate_ctr(train, [\"category\",\"user_preferred_category\"], m=m)\n",
    "    train = train.merge(map_cxp.rename(columns={\"ctr_prior\":\"ctr_prior_cat_x_pref\"}), on=[\"category\",\"user_preferred_category\"], how=\"left\")\n",
    "    test  = test.merge(map_cxp.rename(columns={\"ctr_prior\":\"ctr_prior_cat_x_pref\"}), on=[\"category\",\"user_preferred_category\"], how=\"left\")\n",
    "\n",
    "    map_pref, _ = m_estimate_ctr(train, [\"user_preferred_category\"], m=m)\n",
    "    train = train.merge(map_pref.rename(columns={\"ctr_prior\":\"ctr_prior_pref\"}), on=[\"user_preferred_category\"], how=\"left\")\n",
    "    test  = test.merge(map_pref.rename(columns={\"ctr_prior\":\"ctr_prior_pref\"}), on=[\"user_preferred_category\"], how=\"left\")\n",
    "\n",
    "    map_cpb, _ = m_estimate_ctr(train, [\"category\",\"position_bucket\"], m=m)\n",
    "    train = train.merge(map_cpb.rename(columns={\"ctr_prior\":\"ctr_prior_cat_x_posb\"}), on=[\"category\",\"position_bucket\"], how=\"left\")\n",
    "    test  = test.merge(map_cpb.rename(columns={\"ctr_prior\":\"ctr_prior_cat_x_posb\"}), on=[\"category\",\"position_bucket\"], how=\"left\")\n",
    "\n",
    "    for d in (train, test):\n",
    "        d[\"ctr_prior_category\"] = d[\"ctr_prior_category\"].fillna(global_ctr)\n",
    "        d[\"ctr_prior_cat_x_pref\"] = d[\"ctr_prior_cat_x_pref\"].fillna(global_ctr)\n",
    "        d[\"ctr_prior_pref\"] = d[\"ctr_prior_pref\"].fillna(global_ctr)\n",
    "        d[\"ctr_prior_cat_x_posb\"] = d[\"ctr_prior_cat_x_posb\"].fillna(global_ctr)\n",
    "\n",
    "    return train, test, float(global_ctr)\n",
    "\n",
    "def add_interactions(d: pd.DataFrame, cat_cols) -> pd.DataFrame:\n",
    "    out = d.copy()\n",
    "\n",
    "    out[\"match_x_posb_top3\"] = out[\"category_match\"] * out.get(\"posb_top3\", 0)\n",
    "    out[\"match_x_posb_mid46\"] = out[\"category_match\"] * out.get(\"posb_mid46\", 0)\n",
    "    out[\"match_x_posb_bot710\"] = out[\"category_match\"] * out.get(\"posb_bot710\", 0)\n",
    "\n",
    "    out[\"quality_rank_x_match\"] = out[\"quality_rank_in_session\"] * out[\"category_match\"]\n",
    "    out[\"price_rank_x_match\"] = out[\"price_rank_in_session\"] * out[\"category_match\"]\n",
    "    out[\"quality_pct_x_match\"] = out[\"quality_pct_in_session\"] * out[\"category_match\"]\n",
    "    out[\"price_pct_x_match\"] = out[\"price_pct_in_session\"] * out[\"category_match\"]\n",
    "\n",
    "    out[\"quality_x_log_price\"] = out[\"quality_score\"] * out[\"log_price\"]\n",
    "\n",
    "    for c in cat_cols:\n",
    "        out[f\"{c}_x_quality\"] = out[c] * out[\"quality_score\"]\n",
    "        out[f\"{c}_x_log_price\"] = out[c] * out[\"log_price\"]\n",
    "\n",
    "    return out\n",
    "\n",
    "def build_features_v4(train_raw: pd.DataFrame, test_raw: pd.DataFrame, m=50.0, use_ipw=False):\n",
    "    train = add_core_features(train_raw)\n",
    "    test  = add_core_features(test_raw)\n",
    "\n",
    "    train = add_position_features(train)\n",
    "    test  = add_position_features(test)\n",
    "\n",
    "    train = session_relative_features(train)\n",
    "    test  = session_relative_features(test)\n",
    "\n",
    "    train, test, cat_cols, pref_cols = one_hot_categories(train, test)\n",
    "\n",
    "    train, test, global_ctr = add_ctr_priors(train, test, m=m)\n",
    "\n",
    "    train = add_interactions(train, cat_cols)\n",
    "    test  = add_interactions(test, cat_cols)\n",
    "\n",
    "    if use_ipw:\n",
    "        prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
    "        prop = {str(k): v for k, v in prop.items()}  # Convert dict keys to strings\n",
    "        p_train = train[\"position_bucket\"].astype(str).map(prop).astype(float).fillna(train[\"clicked\"].mean()).clip(0.01, 0.99)\n",
    "        p_test  = test[\"position_bucket\"].astype(str).map(prop).astype(float).fillna(train[\"clicked\"].mean()).clip(0.01, 0.99)\n",
    "        train[\"ipw\"] = 1.0 / p_train\n",
    "        test[\"ipw\"] = 1.0 / p_test\n",
    "    else:\n",
    "        train[\"ipw\"] = 1.0\n",
    "        test[\"ipw\"] = 1.0\n",
    "\n",
    "    base = [\n",
    "        \"pos_boost_clipped3\",\"posb_top3\",\"posb_mid46\",\"posb_bot710\",\n",
    "        \"log_price\",\"quality_price_ratio\",\"category_match\",\n",
    "        \"price_rank_in_session\",\"quality_rank_in_session\",\n",
    "        \"price_pct_in_session\",\"quality_pct_in_session\",\n",
    "        \"price_minus_session_median\",\"quality_minus_session_mean\",\n",
    "        \"price_z_in_session_clipped\",\"quality_z_in_session\",\n",
    "        \"is_cheapest_in_session\",\"is_most_expensive_in_session\",\n",
    "        \"is_best_quality_in_session\",\"is_worst_quality_in_session\",\n",
    "        \"session_size\",\"category_freq_in_session\",\"is_majority_category\",\n",
    "        \"ctr_prior_category\",\"ctr_prior_cat_x_pref\",\"ctr_prior_pref\",\"ctr_prior_cat_x_posb\",\n",
    "        \"match_x_posb_top3\",\"match_x_posb_mid46\",\"match_x_posb_bot710\",\n",
    "        \"quality_rank_x_match\",\"price_rank_x_match\",\"quality_pct_x_match\",\"price_pct_x_match\",\n",
    "    ]\n",
    "\n",
    "    extra = [c for c in train.columns if c.startswith(\"cat_\") or c.startswith(\"pref_\") or c.endswith(\"_x_quality\") or c.endswith(\"_x_log_price\")]\n",
    "    feature_cols = base + extra\n",
    "\n",
    "    for c in feature_cols:\n",
    "        if c not in train.columns: train[c] = 0\n",
    "        if c not in test.columns: test[c] = 0\n",
    "\n",
    "    # Critical: enforce contiguity by session_id before group size computation\n",
    "    train = finalize_order(train)\n",
    "    test  = finalize_order(test)\n",
    "\n",
    "    return train, test, feature_cols, global_ctr\n",
    "\n",
    "# 80/20 split by session_id (as required). Validation is taken from the 80% train portion only.\n",
    "train_full_raw, test_raw = split_by_session(df, seed=42)\n",
    "train_raw, val_raw = split_train_val_from_train(train_full_raw, seed=42, val_fraction=0.1)\n",
    "\n",
    "# Fit features on train only; apply to val/test (priors computed on train only)\n",
    "train_fe, val_fe, feature_cols, global_ctr = build_features_v4(train_raw, val_raw, m=50.0, use_ipw=False)\n",
    "_, test_fe, _, _ = build_features_v4(train_raw, test_raw, m=50.0, use_ipw=False)\n",
    "\n",
    "print(\"Feature count:\", len(feature_cols))\n",
    "train_fe[[\"session_id\",\"product_id\",\"clicked\"] + feature_cols[:15]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bee382",
   "metadata": {},
   "source": [
    "## 3) Train LightGBM Ranker (stability-focused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "883bda45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3743\n",
      "[LightGBM] [Info] Number of data points in the train set: 48698, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's ndcg@5: 0.830477\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's ndcg@5: 0.843408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 train (exclude no-click sessions): 0.7154509526699573\n",
      "NDCG@5 val   (exclude no-click sessions): 0.667047105041002\n",
      "NDCG@5 test  (exclude no-click sessions): 0.6189542697351208\n",
      "NDCG@5 test (include all sessions, no-click => 0): 0.29206904603126005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quality_minus_session_mean</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_x_log_price</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_z_in_session</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_price_ratio</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_price</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_z_in_session_clipped</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_freq_in_session</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_Elektronika_x_quality</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_boost_clipped3</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctr_prior_cat_x_pref</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_pct_in_session</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_pct_x_match</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_minus_session_median</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctr_prior_cat_x_posb</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_Elektronika_x_log_price</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_Odziez_x_log_price</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_Odziez_x_quality</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_pct_in_session</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_rank_x_match</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_rank_in_session</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_Ksiazki_x_log_price</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_pct_x_match</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_Ksiazki_x_quality</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_rank_x_match</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_x_posb_top3</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             importance\n",
       "quality_minus_session_mean          125\n",
       "quality_x_log_price                  73\n",
       "quality_z_in_session                 68\n",
       "quality_price_ratio                  64\n",
       "log_price                            52\n",
       "price_z_in_session_clipped           51\n",
       "category_freq_in_session             44\n",
       "cat_Elektronika_x_quality            43\n",
       "pos_boost_clipped3                   41\n",
       "ctr_prior_cat_x_pref                 41\n",
       "quality_pct_in_session               37\n",
       "price_pct_x_match                    35\n",
       "price_minus_session_median           30\n",
       "ctr_prior_cat_x_posb                 29\n",
       "cat_Elektronika_x_log_price          29\n",
       "cat_Odziez_x_log_price               24\n",
       "cat_Odziez_x_quality                 22\n",
       "price_pct_in_session                 22\n",
       "quality_rank_x_match                 21\n",
       "quality_rank_in_session              20\n",
       "cat_Ksiazki_x_log_price              19\n",
       "quality_pct_x_match                  16\n",
       "cat_Ksiazki_x_quality                16\n",
       "price_rank_x_match                   16\n",
       "match_x_posb_top3                    15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_ranker(train_fe, val_fe, feature_cols, seed=42, use_weights=False):\n",
    "    \"\"\"Train on train_fe, early-stop on val_fe. Do not use the final test set for model selection.\"\"\"\n",
    "    X_train = train_fe[feature_cols]\n",
    "    y_train = train_fe[\"clicked\"].astype(int)\n",
    "    X_val = val_fe[feature_cols]\n",
    "    y_val = val_fe[\"clicked\"].astype(int)\n",
    "\n",
    "    train_group = group_sizes(train_fe, \"session_id\")\n",
    "    val_group = group_sizes(val_fe, \"session_id\")\n",
    "\n",
    "    model = LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        metric=\"ndcg\",\n",
    "        ndcg_eval_at=[5],\n",
    "        n_estimators=8000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=63,\n",
    "        min_data_in_leaf=200,\n",
    "        min_child_samples=None,  # Explicitly disable to avoid warning when min_data_in_leaf is set\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_lambda=2.0,\n",
    "        reg_alpha=0.5,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    fit_kwargs = dict(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        group=train_group,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_group=[val_group],\n",
    "        eval_at=[5],\n",
    "        callbacks=[early_stopping(stopping_rounds=300), log_evaluation(period=300)],\n",
    "    )\n",
    "\n",
    "    if use_weights:\n",
    "        fit_kwargs[\"sample_weight\"] = train_fe[\"ipw\"].astype(float)\n",
    "        fit_kwargs[\"eval_sample_weight\"] = [val_fe[\"ipw\"].astype(float)]\n",
    "\n",
    "    model.fit(**fit_kwargs)\n",
    "\n",
    "    imp = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "    return model, imp\n",
    "\n",
    "\n",
    "def eval_ranker(model, fe, feature_cols, k=5):\n",
    "    X = fe[feature_cols]\n",
    "    y = fe[\"clicked\"].astype(int).to_numpy()\n",
    "    sess = fe[\"session_id\"].to_numpy()\n",
    "\n",
    "    pred = model.predict(X, num_iteration=model.best_iteration_)\n",
    "\n",
    "    ndcg_excl_no_click = ndcg_at_k(y, pred, sess, k=k, ignore_no_positive=True)\n",
    "    ndcg_all_sessions = ndcg_at_k(y, pred, sess, k=k, ignore_no_positive=False)\n",
    "\n",
    "    return pred, float(ndcg_excl_no_click), float(ndcg_all_sessions)\n",
    "\n",
    "\n",
    "model, imp = train_ranker(train_fe, val_fe, feature_cols, seed=42, use_weights=False)\n",
    "\n",
    "pred_train, ndcg_train, ndcg_train_all = eval_ranker(model, train_fe, feature_cols, k=5)\n",
    "pred_val, ndcg_val, ndcg_val_all = eval_ranker(model, val_fe, feature_cols, k=5)\n",
    "pred, ndcg_test, ndcg_test_all = eval_ranker(model, test_fe, feature_cols, k=5)\n",
    "\n",
    "print(\"NDCG@5 train (exclude no-click sessions):\", ndcg_train)\n",
    "print(\"NDCG@5 val   (exclude no-click sessions):\", ndcg_val)\n",
    "print(\"NDCG@5 test  (exclude no-click sessions):\", ndcg_test)\n",
    "\n",
    "print(\"NDCG@5 test (include all sessions, no-click => 0):\", ndcg_test_all)\n",
    "\n",
    "display(imp.head(25).to_frame(\"importance\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a4afc",
   "metadata": {},
   "source": [
    "## 4) Robust evaluation: multi-split CV (mean Â± std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8200e179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3743\n",
      "[LightGBM] [Info] Number of data points in the train set: 48690, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.8132\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's ndcg@5: 0.822269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3748\n",
      "[LightGBM] [Info] Number of data points in the train set: 48703, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.813272\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's ndcg@5: 0.833424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3744\n",
      "[LightGBM] [Info] Number of data points in the train set: 48658, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.825149\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's ndcg@5: 0.829503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3748\n",
      "[LightGBM] [Info] Number of data points in the train set: 48623, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.825377\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's ndcg@5: 0.83452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3747\n",
      "[LightGBM] [Info] Number of data points in the train set: 48694, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.828888\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's ndcg@5: 0.836103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>ndcg@5_train</th>\n",
       "      <th>ndcg@5_val</th>\n",
       "      <th>ndcg@5_test</th>\n",
       "      <th>ndcg@5_test_all_sessions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>0.636589</td>\n",
       "      <td>0.653811</td>\n",
       "      <td>0.307700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0.738752</td>\n",
       "      <td>0.678889</td>\n",
       "      <td>0.640609</td>\n",
       "      <td>0.297082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0.829972</td>\n",
       "      <td>0.632598</td>\n",
       "      <td>0.649975</td>\n",
       "      <td>0.320925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0.723324</td>\n",
       "      <td>0.653897</td>\n",
       "      <td>0.658665</td>\n",
       "      <td>0.314924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>0.684299</td>\n",
       "      <td>0.652669</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.297319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed  ndcg@5_train  ndcg@5_val  ndcg@5_test  ndcg@5_test_all_sessions\n",
       "0    11      0.716305    0.636589     0.653811                  0.307700\n",
       "1    22      0.738752    0.678889     0.640609                  0.297082\n",
       "2    33      0.829972    0.632598     0.649975                  0.320925\n",
       "3    44      0.723324    0.653897     0.658665                  0.314924\n",
       "4    55      0.684299    0.652669     0.630915                  0.297319"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Â± std:\n",
      "NDCG@5 test: 0.6467950133987932 Â± 0.011075770056308545\n",
      "NDCG@5 test (include all sessions, no-click => 0): 0.3075900633891254 Â± 0.01057763461928927\n"
     ]
    }
   ],
   "source": [
    "# Robust evaluation: multi-split CV (mean Â± std)\n",
    "# Train: session-based split, early stopping on validation split carved out of train.\n",
    "\n",
    "\n",
    "def run_cv(df, seeds=(11, 22, 33, 44, 55), m=50.0, use_ipw=False, use_weights=False, val_fraction=0.1):\n",
    "    rows = []\n",
    "    for seed in seeds:\n",
    "        train_full_raw, test_raw = split_by_session(df, seed=seed)\n",
    "        train_raw, val_raw = split_train_val_from_train(train_full_raw, seed=seed, val_fraction=val_fraction)\n",
    "\n",
    "        train_fe, val_fe, feats, _ = build_features_v4(train_raw, val_raw, m=m, use_ipw=use_ipw)\n",
    "        _, test_fe, _, _ = build_features_v4(train_raw, test_raw, m=m, use_ipw=use_ipw)\n",
    "\n",
    "        model, _ = train_ranker(train_fe, val_fe, feats, seed=seed, use_weights=use_weights)\n",
    "\n",
    "        _, nd_train, _ = eval_ranker(model, train_fe, feats, k=5)\n",
    "        _, nd_val, _ = eval_ranker(model, val_fe, feats, k=5)\n",
    "        _, nd_test, nd_test_all_sessions = eval_ranker(model, test_fe, feats, k=5)\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"seed\": seed,\n",
    "                \"ndcg@5_train\": nd_train,\n",
    "                \"ndcg@5_val\": nd_val,\n",
    "                \"ndcg@5_test\": nd_test,\n",
    "                \"ndcg@5_test_all_sessions\": nd_test_all_sessions,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "cv = run_cv(df, seeds=(11, 22, 33, 44, 55), m=50.0, use_ipw=False, use_weights=False, val_fraction=0.1)\n",
    "display(cv)\n",
    "\n",
    "print(\"\\nMean Â± std:\")\n",
    "print(\"NDCG@5 test:\", float(cv[\"ndcg@5_test\"].mean()), \"Â±\", float(cv[\"ndcg@5_test\"].std()))\n",
    "print(\n",
    "    \"NDCG@5 test (include all sessions, no-click => 0):\",\n",
    "    float(cv[\"ndcg@5_test_all_sessions\"].mean()),\n",
    "    \"Â±\",\n",
    "    float(cv[\"ndcg@5_test_all_sessions\"].std()),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a751e6b",
   "metadata": {},
   "source": [
    "## 5) Optional: IPW experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c3050eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Calculating query weights...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3743\n",
      "[LightGBM] [Info] Number of data points in the train set: 48690, number of used features: 46\n",
      "[LightGBM] [Info] Calculating query weights...\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.335299\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's ndcg@5: 0.34277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Calculating query weights...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3748\n",
      "[LightGBM] [Info] Number of data points in the train set: 48703, number of used features: 46\n",
      "[LightGBM] [Info] Calculating query weights...\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.377162\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's ndcg@5: 0.384331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Calculating query weights...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3744\n",
      "[LightGBM] [Info] Number of data points in the train set: 48658, number of used features: 46\n",
      "[LightGBM] [Info] Calculating query weights...\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.318428\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's ndcg@5: 0.3221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Calculating query weights...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3748\n",
      "[LightGBM] [Info] Number of data points in the train set: 48623, number of used features: 46\n",
      "[LightGBM] [Info] Calculating query weights...\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.336977\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's ndcg@5: 0.34448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/var/folders/v6/xzrdvw71737cqqc8m_0c1s1w0000gp/T/ipykernel_60128/3891775666.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  prop = train.groupby(\"position_bucket\")[\"clicked\"].mean().to_dict()\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Calculating query weights...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3747\n",
      "[LightGBM] [Info] Number of data points in the train set: 48694, number of used features: 46\n",
      "[LightGBM] [Info] Calculating query weights...\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.33015\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's ndcg@5: 0.338273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>ndcg@5_train</th>\n",
       "      <th>ndcg@5_val</th>\n",
       "      <th>ndcg@5_test</th>\n",
       "      <th>ndcg@5_test_all_sessions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.764005</td>\n",
       "      <td>0.634068</td>\n",
       "      <td>0.657799</td>\n",
       "      <td>0.309577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0.725196</td>\n",
       "      <td>0.673884</td>\n",
       "      <td>0.639176</td>\n",
       "      <td>0.296418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0.827802</td>\n",
       "      <td>0.621303</td>\n",
       "      <td>0.649767</td>\n",
       "      <td>0.320823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0.726547</td>\n",
       "      <td>0.651622</td>\n",
       "      <td>0.651883</td>\n",
       "      <td>0.311682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>0.673399</td>\n",
       "      <td>0.653583</td>\n",
       "      <td>0.635847</td>\n",
       "      <td>0.299643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed  ndcg@5_train  ndcg@5_val  ndcg@5_test  ndcg@5_test_all_sessions\n",
       "0    11      0.764005    0.634068     0.657799                  0.309577\n",
       "1    22      0.725196    0.673884     0.639176                  0.296418\n",
       "2    33      0.827802    0.621303     0.649767                  0.320823\n",
       "3    44      0.726547    0.651622     0.651883                  0.311682\n",
       "4    55      0.673399    0.653583     0.635847                  0.299643"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Â± std (IPW):\n",
      "NDCG@5 test: 0.6468944992685823 Â± 0.009133700829567545\n",
      "NDCG@5 test (include all sessions, no-click => 0): 0.3076283373258502 Â± 0.009794965101263674\n"
     ]
    }
   ],
   "source": [
    "cv_ipw = run_cv(df, seeds=(11, 22, 33, 44, 55), m=50.0, use_ipw=True, use_weights=True, val_fraction=0.1)\n",
    "display(cv_ipw)\n",
    "\n",
    "print(\"\\nMean Â± std (IPW):\")\n",
    "print(\"NDCG@5 test:\", float(cv_ipw[\"ndcg@5_test\"].mean()), \"Â±\", float(cv_ipw[\"ndcg@5_test\"].std()))\n",
    "print(\n",
    "    \"NDCG@5 test (include all sessions, no-click => 0):\",\n",
    "    float(cv_ipw[\"ndcg@5_test_all_sessions\"].mean()),\n",
    "    \"Â±\",\n",
    "    float(cv_ipw[\"ndcg@5_test_all_sessions\"].std()),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae6e1ce",
   "metadata": {},
   "source": [
    "## 6) Export predictions.csv (seed=42 test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69015159",
   "metadata": {},
   "source": [
    "## Part 3: Business summary & results export\n",
    "\n",
    "Generate `results.json` with all required sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "718ed209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Results:\n",
      "{\n",
      "  \"candidate_info\": {\n",
      "    \"language_used\": \"Python\",\n",
      "    \"time_spent_hours\": 8.0\n",
      "  },\n",
      "  \"data_analysis\": {\n",
      "    \"overall_ctr\": 0.0767,\n",
      "    \"position_bias_ratio\": 3.42,\n",
      "    \"electronics_ctr\": 0.1219,\n",
      "    \"quality_correlation\": 0.1198,\n",
      "    \"best_category\": \"Elektronika\"\n",
      "  },\n",
      "  \"model_performance\": {\n",
      "    \"algorithm_used\": \"LightGBM\",\n",
      "    \"ndcg_at_5\": 0.619,\n",
      "    \"features_count\": 46,\n",
      "    \"top_features\": [\n",
      "      \"quality_minus_session_mean\",\n",
      "      \"quality_x_log_price\"\n",
      "    ]\n",
      "  },\n",
      "  \"business_analysis\": {\n",
      "    \"expected_ctr_lift_percent\": 15,\n",
      "    \"main_risk\": \"Position bias amplification (features include position; offline clicks are position-biased). Validate via A/B test and consider debiasing/counterfactual training.\",\n",
      "    \"recommendation\": \"test\"\n",
      "  }\n",
      "}\n",
      "\n",
      "â results.json saved successfully\n",
      "â predictions.csv saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Generate complete results.json\n",
    "\n",
    "TIME_SPENT_HOURS = 8.0  # keep consistent across artifacts\n",
    "\n",
    "# IMPORTANT: report TEST NDCG@5 (not training), using the standard convention of\n",
    "# excluding sessions with no positive labels (no-click sessions).\n",
    "model_performance = {\n",
    "    \"algorithm_used\": \"LightGBM\",\n",
    "    \"ndcg_at_5\": round(float(ndcg_test), 4),\n",
    "    \"features_count\": int(len(feature_cols)),\n",
    "    \"top_features\": imp.head(2).index.tolist(),\n",
    "}\n",
    "\n",
    "# Business Analysis\n",
    "# Note: mapping offline NDCG to CTR lift is not direct; treat this as a hypothesis to validate via A/B.\n",
    "expected_ctr_lift_percent = 15\n",
    "\n",
    "main_risk = (\n",
    "    \"Position bias amplification (features include position; offline clicks are position-biased). \"\n",
    "    \"Validate via A/B test and consider debiasing/counterfactual training.\"\n",
    ")\n",
    "recommendation = \"test\"\n",
    "\n",
    "business_analysis = {\n",
    "    \"expected_ctr_lift_percent\": expected_ctr_lift_percent,\n",
    "    \"main_risk\": main_risk,\n",
    "    \"recommendation\": recommendation,\n",
    "}\n",
    "\n",
    "candidate_info = {\n",
    "    \"language_used\": \"Python\",\n",
    "    \"time_spent_hours\": TIME_SPENT_HOURS,\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"candidate_info\": candidate_info,\n",
    "    \"data_analysis\": data_analysis,\n",
    "    \"model_performance\": model_performance,\n",
    "    \"business_analysis\": business_analysis,\n",
    "}\n",
    "\n",
    "with open(\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Complete Results:\")\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))\n",
    "print(f\"\\nâ results.json saved successfully\")\n",
    "print(f\"â predictions.csv saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b4c0ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>actual_clicked</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>prod_17_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>prod_17_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>prod_17_3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.293710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>prod_17_4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>prod_17_5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.231431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id product_id  actual_clicked  predicted_score\n",
       "0          17  prod_17_1               0         0.088004\n",
       "1          17  prod_17_2               0         0.182742\n",
       "2          17  prod_17_3               0        -0.293710\n",
       "3          17  prod_17_4               0        -0.000457\n",
       "4          17  prod_17_5               0        -0.231431"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_out = test_fe[[\"session_id\",\"product_id\"]].copy()\n",
    "pred_out[\"actual_clicked\"] = test_fe[\"clicked\"].astype(int).to_numpy()\n",
    "pred_out[\"predicted_score\"] = pred\n",
    "pred_out.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "pred_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ed49dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3743\n",
      "[LightGBM] [Info] Number of data points in the train set: 48690, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.8132\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's ndcg@5: 0.822269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3716\n",
      "[LightGBM] [Info] Number of data points in the train set: 48690, number of used features: 38\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.748127\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@5: 0.764754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3748\n",
      "[LightGBM] [Info] Number of data points in the train set: 48703, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.813272\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's ndcg@5: 0.833424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3721\n",
      "[LightGBM] [Info] Number of data points in the train set: 48703, number of used features: 38\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.753424\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@5: 0.768621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3744\n",
      "[LightGBM] [Info] Number of data points in the train set: 48658, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.825149\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's ndcg@5: 0.829503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3717\n",
      "[LightGBM] [Info] Number of data points in the train set: 48658, number of used features: 38\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.757561\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@5: 0.779958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3748\n",
      "[LightGBM] [Info] Number of data points in the train set: 48623, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.825377\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's ndcg@5: 0.83452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3721\n",
      "[LightGBM] [Info] Number of data points in the train set: 48623, number of used features: 38\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.767273\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's ndcg@5: 0.787738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3747\n",
      "[LightGBM] [Info] Number of data points in the train set: 48694, number of used features: 46\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.828888\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's ndcg@5: 0.836103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3720\n",
      "[LightGBM] [Info] Number of data points in the train set: 48694, number of used features: 38\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\tvalid_0's ndcg@5: 0.764799\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@5: 0.780051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data-science/lib/python3.11/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>ndcg@5_test_pos_only</th>\n",
       "      <th>ndcg@5_test_qpr_only</th>\n",
       "      <th>ndcg@5_test_full</th>\n",
       "      <th>ndcg@5_test_no_pos</th>\n",
       "      <th>ndcg@5_test_full_all_sessions</th>\n",
       "      <th>ndcg@5_test_no_pos_all_sessions</th>\n",
       "      <th>n_features_full</th>\n",
       "      <th>n_features_no_pos</th>\n",
       "      <th>pos_feature_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.628691</td>\n",
       "      <td>0.518285</td>\n",
       "      <td>0.653811</td>\n",
       "      <td>0.539937</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.254108</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0.616157</td>\n",
       "      <td>0.496397</td>\n",
       "      <td>0.640609</td>\n",
       "      <td>0.521636</td>\n",
       "      <td>0.297082</td>\n",
       "      <td>0.241909</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0.631010</td>\n",
       "      <td>0.523750</td>\n",
       "      <td>0.649975</td>\n",
       "      <td>0.565795</td>\n",
       "      <td>0.320925</td>\n",
       "      <td>0.279361</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0.627556</td>\n",
       "      <td>0.497434</td>\n",
       "      <td>0.658665</td>\n",
       "      <td>0.523201</td>\n",
       "      <td>0.314924</td>\n",
       "      <td>0.250156</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>0.609911</td>\n",
       "      <td>0.508788</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.547167</td>\n",
       "      <td>0.297319</td>\n",
       "      <td>0.257852</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed  ndcg@5_test_pos_only  ndcg@5_test_qpr_only  ndcg@5_test_full  ndcg@5_test_no_pos  ndcg@5_test_full_all_sessions  ndcg@5_test_no_pos_all_sessions  n_features_full  n_features_no_pos  \\\n",
       "0    11              0.628691              0.518285          0.653811            0.539937                       0.307700                         0.254108               46                 38   \n",
       "1    22              0.616157              0.496397          0.640609            0.521636                       0.297082                         0.241909               46                 38   \n",
       "2    33              0.631010              0.523750          0.649975            0.565795                       0.320925                         0.279361               46                 38   \n",
       "3    44              0.627556              0.497434          0.658665            0.523201                       0.314924                         0.250156               46                 38   \n",
       "4    55              0.609911              0.508788          0.630915            0.547167                       0.297319                         0.257852               46                 38   \n",
       "\n",
       "   pos_feature_count  \n",
       "0                  8  \n",
       "1                  8  \n",
       "2                  8  \n",
       "3                  8  \n",
       "4                  8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Â± std (CV, TEST):\n",
      "ndcg@5_test_pos_only: 0.6227 Â± 0.0091\n",
      "ndcg@5_test_qpr_only: 0.5089 Â± 0.0122\n",
      "ndcg@5_test_full: 0.6468 Â± 0.0111\n",
      "ndcg@5_test_no_pos: 0.5395 Â± 0.0183\n",
      "ndcg@5_test_full_all_sessions: 0.3076 Â± 0.0106\n",
      "ndcg@5_test_no_pos_all_sessions: 0.2567 Â± 0.0140\n"
     ]
    }
   ],
   "source": [
    "# --- Robustness checks: position baseline + no-position ablation ---\n",
    "\n",
    "\n",
    "def _split_feature_sets(feature_cols):\n",
    "    \"\"\"Return (position_related, non_position) feature lists.\"\"\"\n",
    "    pos_feats = []\n",
    "    for c in feature_cols:\n",
    "        if (\n",
    "            c.startswith(\"pos_\")\n",
    "            or c.startswith(\"posb_\")\n",
    "            or (\"position_bucket\" in c)\n",
    "            or (\"_posb_\" in c)\n",
    "            or (c in {\"pos_boost_clipped3\", \"ctr_prior_cat_x_posb\"})\n",
    "        ):\n",
    "            pos_feats.append(c)\n",
    "\n",
    "    pos_feats = sorted(set(pos_feats))\n",
    "    non_pos = [c for c in feature_cols if c not in set(pos_feats)]\n",
    "    return pos_feats, non_pos\n",
    "\n",
    "\n",
    "def run_cv_feature_sets(\n",
    "    df,\n",
    "    seeds=(11, 22, 33, 44, 55),\n",
    "    m=50.0,\n",
    "    k=5,\n",
    "    val_fraction=0.1,\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        train_full_raw, test_raw = split_by_session(df, seed=seed)\n",
    "        train_raw, val_raw = split_train_val_from_train(train_full_raw, seed=seed, val_fraction=val_fraction)\n",
    "\n",
    "        train_fe, val_fe, feats_full, _ = build_features_v4(train_raw, val_raw, m=m, use_ipw=False)\n",
    "        _, test_fe, _, _ = build_features_v4(train_raw, test_raw, m=m, use_ipw=False)\n",
    "\n",
    "        pos_feats, feats_no_pos = _split_feature_sets(feats_full)\n",
    "\n",
    "        # Baselines on TEST\n",
    "        y = test_fe[\"clicked\"].astype(int).to_numpy()\n",
    "        sess = test_fe[\"session_id\"].to_numpy()\n",
    "\n",
    "        score_pos_only = test_fe[\"pos_boost_clipped3\"].to_numpy()\n",
    "        ndcg_pos_only = ndcg_at_k(y, score_pos_only, sess, k=k, ignore_no_positive=True)\n",
    "\n",
    "        score_qpr = test_fe[\"quality_price_ratio\"].to_numpy()\n",
    "        ndcg_qpr = ndcg_at_k(y, score_qpr, sess, k=k, ignore_no_positive=True)\n",
    "\n",
    "        # Full model (train+val protocol)\n",
    "        model_full, _ = train_ranker(train_fe, val_fe, feats_full, seed=seed, use_weights=False)\n",
    "        _, ndcg_full, ndcg_full_all_sessions = eval_ranker(model_full, test_fe, feats_full, k=k)\n",
    "\n",
    "        # No-position-features model\n",
    "        model_nopos, _ = train_ranker(train_fe, val_fe, feats_no_pos, seed=seed, use_weights=False)\n",
    "        _, ndcg_nopos, ndcg_nopos_all_sessions = eval_ranker(model_nopos, test_fe, feats_no_pos, k=k)\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"seed\": seed,\n",
    "                \"ndcg@5_test_pos_only\": float(ndcg_pos_only),\n",
    "                \"ndcg@5_test_qpr_only\": float(ndcg_qpr),\n",
    "                \"ndcg@5_test_full\": float(ndcg_full),\n",
    "                \"ndcg@5_test_no_pos\": float(ndcg_nopos),\n",
    "                \"ndcg@5_test_full_all_sessions\": float(ndcg_full_all_sessions),\n",
    "                \"ndcg@5_test_no_pos_all_sessions\": float(ndcg_nopos_all_sessions),\n",
    "                \"n_features_full\": int(len(feats_full)),\n",
    "                \"n_features_no_pos\": int(len(feats_no_pos)),\n",
    "                \"pos_feature_count\": int(len(pos_feats)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    display(out)\n",
    "\n",
    "    def _mean_std(col):\n",
    "        return float(out[col].mean()), float(out[col].std())\n",
    "\n",
    "    print(\"\\nMean Â± std (CV, TEST):\")\n",
    "    for col in [\n",
    "        \"ndcg@5_test_pos_only\",\n",
    "        \"ndcg@5_test_qpr_only\",\n",
    "        \"ndcg@5_test_full\",\n",
    "        \"ndcg@5_test_no_pos\",\n",
    "        \"ndcg@5_test_full_all_sessions\",\n",
    "        \"ndcg@5_test_no_pos_all_sessions\",\n",
    "    ]:\n",
    "        mu, sd = _mean_std(col)\n",
    "        print(f\"{col}: {mu:.4f} Â± {sd:.4f}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "robust_cv = run_cv_feature_sets(df, seeds=(11, 22, 33, 44, 55), m=50.0, k=5, val_fraction=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
